\documentclass[conference]{IEEEtran}
\usepackage{times}

%  For math environment
\usepackage{amsmath,amssymb,amsthm}

%  For todo notes
\usepackage{todonotes}

%  For drawing Bayesian networks
\usepackage{tikz}
\usetikzlibrary{arrows,positioning}
\usepackage{tikz-cd}

%  For theorems, etc
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}

% numbers option provides compact numerical references in the text. 
\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage[bookmarks=true]{hyperref}

% Custom commands
\newcommand{\pder}[2]{\ensuremath{\frac{\partial #1}{\partial #2}}}

\pdfinfo{
   /Author (Hal 9000)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)
}

\begin{document}

% paper title
\title{Real-Time Probabilistic Pedestrian Forecasting}

% You will get a Paper-ID when submitting a pdf file to the conference system
\author{Author Names Omitted for Anonymous Review. Paper-ID [add your ID here]}

%\author{\authorblockN{Michael Shell}
%\authorblockA{School of Electrical and\\Computer Engineering\\
%Georgia Institute of Technology\\
%Atlanta, Georgia 30332--0250\\
%Email: mshell@ece.gatech.edu}
%\and
%\authorblockN{Homer Simpson}
%\authorblockA{Twentieth Century Fox\\
%Springfield, USA\\
%Email: homer@thesimpsons.com}
%\and
%\authorblockN{James Kirk\\ and Montgomery Scott}
%\authorblockA{Starfleet Academy\\
%San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212\\
%Fax: (888) 555--1212}}


% avoiding spaces at the end of the author lines is not a problem with
% conference papers because we don't use \thanks or \IEEEmembership


% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\authorblockN{Michael Shell\authorrefmark{1},
%Homer Simpson\authorrefmark{2},
%James Kirk\authorrefmark{3}, 
%Montgomery Scott\authorrefmark{3} and
%Eldon Tyrell\authorrefmark{4}}
%\authorblockA{\authorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: mshell@ece.gatech.edu}
%\authorblockA{\authorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\authorblockA{\authorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\authorblockA{\authorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}


\maketitle

\begin{abstract}
The abstract goes here.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}

Autonomous systems acting in human-centric environments should be able to anticipate the behavior of neighboring humans to ensure safe operation. 
Anticipating the future locations of individuals within a scene, for instance, is critical to synthesizing safe controllers for autonomous vehicles.
To aid during safe control design for such systems, a prediction algorithm must satisfy several important criteria.
First, since safety is paramount, the prediction algorithm should avoid misclassifying areas as unoccupied.
Second, the predictions must be generated at faster than real-time rates to ensure that they can be used within a control loop.
Finally, long-time horizon forecasts are preferable since they can make planning over long-time horizons feasible, which can reduce the conservativeness and aggressiveness of controllers \cite{}.

This paper presents an algorithm for real-time, long-term prediction of pedestrian behavior which can subsequently be used by autonomous agents.

As depicted in Figure \ref{fig:}, this approach relies upon ... 
The presented approach significantly outperforms...

%First, since safety is paramount, generated predictions must avoid misclassifying areas as unoccupied even though humans are present. 
%Though this may unduly reduce the precision of the algorithm 

\subsection{Background}
Most forecasting algorithm are well characterized by the underlying evolution model they adopt.
Such models come in a variety flavors, and are adapted to the task at hand.
For example, see \cite{Helbing1992} for crowd modeling.

In this article we are primarily concerned with models that probabilistically predict the position of a single agent.
The most simple approach to forecasting would be to forward integrate a Kalman filter \cite{kalman1960new} based upon the observed heading.
Over short time scales this may perform quite well, but the resulting distribution will devolve into a large Gaussian mass over longer time scales.
To mitigate the negative effects of this simplistic description of motion, slightly more sophisticated motion models should be considered.
Such models include inverse optimal control (IOC) based models such as \cite{Ziebart2008,Ziebart2009,Kitani2012}.
These IOC models have the often desirable property of attributing intention and goal-seeking behavior to the agents.
For example \citet{Kitani2012} extracted a very simple Markov decision process (MDP) evolving on a 2D lattice by training on a small collection of features and trajectories.
The resulting MDP is very light weight, parametrized by only a small collection of coefficients equal in number to that of the feature maps.
Secondly, given an initial and final state, the probability distribution of the pedestrian at intermediate states is easily computable because it basically comes down to matrix multiplication.
Thirdly, the small collection of parameters learned in one environment can, in principal, be used in a novel environment without retraining (i.e. ``knowledge transfer'').
Lastly, the IOC-MDP framework is very flexible and very easy to generalize.
For example, time dependent information, such as traffic signals, are incorporated in \cite{Karasev2016}, by relaxing the Markov property and considering a switched Markov process.
\citet{Karasev2016} generalizes \cite{Kitani2012} further by considering a discrete time Markov process over a continuous space which more closely approximates reality.
However, this modelling choice resulted in posteriors which were difficult to compute with precision.
They opted to use a sample based method: a Rao-Blackwellized particle filter.
The resulting accuracy is known in a probabilistic sense in that the error bounds are themselves random variables.
Moreover, high accuracy can come at a high computational cost prohibitive for real-time computation.
It should be noted, however, that speed was not a goal of \cite{Karasev2016}.

One difficulty which IOC models can suffer, is the tendency for the trajectories to become trapped in local optimal.
This often occurs when agents make very sharp turns, and have intermediate goals to go one place before visiting another.
To address this, \citet{Ballan2016} adopted an empiricists approach, computing ``turning maps'' and attempting to infer how agents behave in a given patch based on it's feature, solely based on how previous agents have behaved there (regardless of operating under an unobserved optimization criteria).
Similar to \cite{Karasev2016}, the motion model was a discrete time Markov process over a continuous space and so the relevant posteriors were approximated using sample based techniques.
Again, the same criticisms in regards to speed an accuracy lodged at \cite{Karasev2016} can also be lodged at \cite{Ballan2016}, and again, we should note that speed/high accuracy were not a priority there.
However, the motion model of \citet{Ballan2016} was merely an illustrative choice in the more ambitious pursuit of creating a flexible paradigm for pedestrian forecasting.
In particular, a motion model on one scene ought to be transferable to other scenes, and the representation of the ``objects'' in the scene ought to be flexible in order for behavior to be robust.
Said differently, the way a forecasting algorithm executes ``knowledge transfer'' should not depend too rigidly on the finitely many labels some engineer managed to think of in a late-night brainstorming session.
The algorithm should be able to infer how to behave near a roundabout by using prior knowledge of more fundamental building blocks like pavement, curbs, and asphalt.
In summary, the motion model used in \cite{Ballan2016} is merely a parameter of the more general framework they have proposed.
We should note that the motion model we will present here can, in principal, be incorporated within their forecasting paradigm.

Finally,

\subsection{Contributions}

The primary contributions of this paper are:

The rest of the paper is organized as follows:

\section{Model}

\todo[inline]{ramv: I would include far fewer model details here just to illustrate that our focus is on efficient computation for general models.}

%Describe scenario in english.
Our goal is to generate a time-dependent probability density over $\mathbb{R}^2$, which predicts the true location of an agent in the future.
The input to the algorithm at runtime is a noisy measurement of position and velocity, $\hat{x}_0, \hat{v}_0 \in \mathbb{R}^2$.
If the (unknown) location of agent at time $t$ is given by $x_t \in \mathbb{R}^2$, then the distribution we seek is the posterior $\rho_t(x_t) := \Pr( x_t \mid \hat{x}_0, \hat{v}_0 )$.

In order to derive an expression for $\rho$ we will build a probabilistic graphical model.
Our model assumes we have noisy information about agents, and each agent moves with some intention through the world in a way that is roughly approximated by a model.
This allows our model to be divided into three parts:
\begin{enumerate}
	\item Reality:  This is parametrized by the true position for all time, $x_t$, and the initial velocity of the agent $v_0$.
	\item The measurements:  This is represented by our sensor readings $\hat{x}_0$ and $\hat{v}_0$ and are independent of all other variables given the true initial position and velocity, $x_o, v_0$.
	\item The motion model:  This is represented by a trajectory $\check{x}_t$ and depends on a variety of other variables which will be described shortly.
\end{enumerate}
We will now elaborate on these three components, and relate them to one another.

\subsection{The Sensor Model}
At time $t=0$, we obtain a noisy reading of position, $\hat{x}_0 \in \mathbb{R}^2$.
We assume that our measurements come from Gaussian noise about the true location $x_0 \in \mathbb{R}^2$.
In other words $\Pr( \hat{x}_0 \mid x_0 ) = G_{\sigma_x}( \hat{x}_0 - x_0 )$ where $G_\sigma$ denotes the bivariate Gaussian distribution.
We use the same sensor model is assumed for velocity in that $\Pr( \hat{v}_0 \mid v_0 ) = G_{\sigma_v}( \hat{v}_0 - v_0 )$.
In principal, any measurement model could be used, and we may view this as a parameter of our method.

\subsection{The Agent Model}
All agents are initialized within some rectangular region $D \subset \mathbb{R}^2$.
We denote the true position of an agent by $x_t$.
We should never expect to know $x_t$ and the nature of its evolution precisely, and any model should account for its own (inevitable) imprecision.
We do this by fitting a deterministic model to the data and blurring the result in order to acknowledge inevitable modeling errors.

Specifically, our motion model consists of a modeled trajectory $\check{x}_t$, which is probabilistically related to the true position by $x_t$ via 
\begin{align*}
	\Pr( x_t \mid \check{x}_t ) \sim \mathcal{N}( \check{x}_t, \sigma_{int}(t)),
\end{align*}
where $\sigma_{int}(t) = \kappa t$ for some learned constant $\kappa > 0$.
This insures the consistency condition $\check{x}_0 = x_0$, while acknowledging the existence of uncertainty for all $t>0$.

Once initialized, agents come in two flavors: linear and nonlinear.
Linear agents evolve in time according to the equation $\check{x}_t = x_0 + t v_0$ and so we have the posterior
\begin{align*}
	\Pr( \check{x}_t \mid x_0, v_0, lin) = \delta( \check{x}_t - x_0 - t v_0 ).
\end{align*}
We will assume linear agents also satisfy the posteriors
\begin{align*}
	\Pr( x_0 \mid lin ) \sim \mathcal{U}( D)\quad,\quad \Pr( v_0 \mid lin ) \sim \mathcal{N}( 0 , \sigma_L).
\end{align*}

If the agent is of nonlinear type, then we assume the dynamics take the form
\begin{align}
	\frac{d \check{x}_t}{dt} = s \cdot X_k(\check{x}_t) \label{eq:ode}
\end{align}
where $X_k$ is a vector-field from a finite collection $\{X_1, \dots, X_n\}$, and $s \in \mathbb{R}$.
More specifically, we assume that each $X_k$ has the property that $\| X_k(x) \| = 1$ for all $x \in D$.
This property ensures that speed is constant in time, and it has the further advantage of being the (local) generator
of solutions to an optimal navigation problem (see Appendix \ref{app:ioc}).
The vector-fields $X_1,\dots,X_n$ are learned from the data-set (see \S \ref{sec:implementation}).

It is assumed that $k$ and $s$ are both constant in time, so that $\check{x}_t$ is determined from the
tripe $(x_0,k,s)$ by integrating \eqref{eq:ode} with the initial condition $x_0$.
In other words, we have the posterior
\begin{align}
	\Pr( \check{x}_t \mid x_0 , k , s) = \delta( \check{x}_t - \Phi^{t}_{k,s}( x_0) ) \label{eq:x_check | ksx}
\end{align}
where $\Phi^{t}_{k,s}$ is the flow-map of the vector field $s \,X_k$ up to time $t$.
It is notable, that the variables $k,s$ and $x_0$ determine $v_0$.
Thus we also have the posterior
\begin{align}
	\Pr( v_0 \mid k, s, x_0) = \delta( v_0 -s X_k( x_0) ). \label{eq:v | ksx}
\end{align}
In summary, the agent flavors are parametrized by the set
\begin{align}
	F = \{ lin \} \cup \left( \mathbb{R} \times \{ 1 , \dots, n \} \right) \label{eq:flavors}
\end{align}
and each flavor determines the sort of motion we should expect from that agent.
\subsection{The Full Model}
Concatenating the measurement model with our motion model yields the Bayesian network, where $f$ is an element of $F$ from \eqref{eq:flavors} and denotes the flavor of the agent:
\begin{center}
\begin{tikzpicture}[thick, var/.style={circle,draw,thin,rounded corners,shade,top color=blue!50,minimum size = 4mm}]
	\node[var] (f) {$f$};
	\node[var] (x)[right=of f] {$x_0$};
	\node[var] (v)[below=of x] {$v_0$};
	\node[var] (x_hat) [right=of x] {$\hat{x}_0$};
	\node[var] (v_hat) [right=of v] {$\hat{v}_0$};
	\node[var] (x_check_t) [left=of v] {$\check{x}_t$};
	\node[var] (x_t) [left=of x_check_t] {$x_t$};
	\draw[->] (f) to (x);
	\draw[->] (f) to (v);
	\draw[->] (f.south) to (x_check_t.north);
	\draw[->] (x.east) to (x_hat.west);
	\draw[->] (x) to (x_check_t);
	\draw[->] (x) to (v);
	\draw[->] (v) to (x_check_t);
	\draw[->] (v.east) to (v_hat.west);
	\draw[->] (x_check_t) to (x_t); 
\end{tikzpicture}.
\end{center}
We may use this Bayesian network to compute $\rho_t$ efficiently.
In particular
\begin{align*}
	\rho_t(x_t ) &:= \Pr( x_t \mid \hat{x}_0, \hat{v}_0 ) \\
	&= \left( \sum_{k} \int \Pr( x_t, k , s  \mid \hat{x}_0, \hat{v}_0 ) ds \right) \\
	&\quad + \Pr( x_t, lin \mid \hat{x}_0, \hat{v}_0 ).
\end{align*}
The final term $\Pr( x_t, lin \mid \hat{x}_0, \hat{v}_0 )$ is expressible in terms of the error function, and would pose a negligible burden in terms of numerical computation.
The primary computational burden derives from the sum $\sum_{k} \int \Pr( x_t, k , s  \mid \hat{x}_0, \hat{v}_0 ) ds$.
%\todo[inline]{hoj: May I cut the following?  If I say ``PGM'' or ``Bayesian network'' perhaps that enough to convey the sort of computations needed}
%Specifically, the vector-fields $\{X_1,\dots,X_n\}$ as well as the probabilities $\Pr( x_0 \mid k )$, $\Pr(lin)$, and $\Pr( k )$ will be learned from the data.
%We will also assume $\Pr(s,k) = \Pr(s \mid k ) \Pr(k)$ where 
%\begin{align*}
%	\Pr(s \mid k ) \sim \mathcal{U}([-s_{\max}, s_{\max} ] ) \quad \text{for } k=1,\dots,n
%\end{align*}
%and $s_{\max} > 0$ is learned from the data.
%We describe the learning step in more detail in section \ref{sec:learning}.
%
%The desired posterior, $\rho_t$ is a posterior over $D$ given by
%\begin{align*}
%	&\rho_t(x_t) = \Pr(x_t \mid \hat{x}_0, \hat{v}_0) \\
%		&= \frac{ \Pr( x_t, \hat{x}_0, \hat{v}_0) }{ \Pr( \hat{x}_0, \hat{v}_0 ) } \\
%		&= \frac{1}{ \Pr( \hat{x}_0, \hat{v}_0 ) } \int \Pr( x_t , x_0, v_0, \hat{x}_0, \hat{v}_0 , f ) dx_0\, dv_0\, df
%\end{align*}
%and the integrand is given, via the Bayesian network.
%In particular, for $f = (k,s)$ we have
%\begin{align*}
%	 &\Pr( x_t , x_0, v_0, \hat{x}_0, \hat{v}_0 , k,s) =\\
%	 &\quad \Pr( x_t \mid x_0 , k, s) \cdot \Pr( v_0 \mid x_0, k , s ) \cdot \\
%	 &\quad \Pr( \hat{x}_0 \mid x_0 ) \cdot \Pr( \hat{v}_0 \mid v_0 ) \cdot \Pr(k) \cdot \Pr(s \mid k),
%\end{align*}
%and for $f = lin$ we have
%\begin{align*}
%	 &\Pr( x_t , x_0, v_0, \hat{x}_0, \hat{v}_0 , lin) =\\
%	 &\quad \Pr( x_t \mid x_0 , v_0, lin) \cdot \Pr( v_0 \mid x_0, lin ) \cdot \\
%	 &\quad \Pr( \hat{x}_0 \mid x_0 ) \cdot \Pr( \hat{v}_0 \mid v_0 ) \cdot \Pr(lin).
%\end{align*}


\section{Efficient Probability Propagation} \label{sec:efficient}
As mentioned \todo{hoj: Make sure we mention this.}, many of the modeling choices were born out of a balance between accuracy and real-time computability.
One of the major modeling choices, that agents move approximately according to a small number of ODEs, is the most prominent such choice.
In this section we give some details on how this modeling choice can be leveraged to compute $\rho$ quickly, and accurately.
In particular, we illustrate how to compute an accurate approximation of the the posterior $\Pr( x_t, k,s \mid \hat{x}_0, \hat{v}_0)$.

To begin, from the graphical model we can see that
\begin{align*}
	&\Pr( x_t, k,s,\mid \hat{x}_0, \hat{v}_0) \propto \Pr( x_t, k,s,\hat{x}_0, \hat{v}_0) \\
	&= \int \Pr( x_t, \check{x}_t , \hat{x}_0, \hat{v}_0, k,s) d\check{x}_t \\
	&= \int \Pr( x_t \mid \check{x}_t ) \Pr(\check{x}_t , \hat{x}_0, \hat{v}_0, k,s) d\check{x}_t
\end{align*}
As $\Pr( x_t \mid \check{x}_t) \sim \mathcal{N}( \check{x}_t ; \kappa t)$, we see from the last line that $\Pr( x_t, k,s,\mid \hat{x}_0, \hat{v}_0)$ is proportional to a Gaussian convolution of
of the joint distribution $\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s)$.
Assuming such a convolution can be performed efficiently (which we will address later), we can focus on computation of $\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s)$.

Again, from the PGM we see that
\begin{align}
	&\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s) = \int \Pr( \check{x}_t , x_0, \hat{x}_0, v_0, \hat{v}_0, k,s) dx_0 \, dv_0 \\
		&=  \int \Pr( \check{x}_t \mid  x_0, k,s, v_0) \Pr( \hat{v}_0 \mid v_0) \Pr( v_0 \mid k,s,x_0) \\
		& \hspace{20ex} \Pr(\hat{x}_0, x_0, k, s) dx_0 \, dv_0 \\
\end{align}
Substitution of \eqref{eq:x_check | ksx} and \eqref{eq:v | ksx} yeilds
\begin{align}
		&= \int \delta\left( \check{x}_t - \Phi_{k,s}^{t}( x_0) \right) \delta\left( v_0 - s X_k (x_0) \right) \\
		&\hspace{20ex}\Pr( \hat{v}_0 \mid v_0) \Pr(\hat{x}_0, x_0,k, s) dx_0\, dv_0
\end{align}
Carrying out the integration over $v_0$ we observe
\begin{align}
\begin{split}
	&\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s) \\
	&= \int \delta\left( \check{x}_t - \Phi_{k,s}^{t}( x_0) \right) \Pr(\hat{x}_0, x_0, k, s) G_{\sigma_v}( \hat{v}_0 - s X_k(x_0) ) dx_0
\end{split}
\label{eq:push forward}
\end{align}
 As the density $\Pr(\hat{x}_0, x_0, k, s) G_{\sigma_v}( \hat{v}_0 - s X_k(x_0) )$ is Riemann integrable in $x_0$,
 we may approximate it as a sum of weighted Dirac delta's supported on a regular grid, $\Gamma = \cup_{\alpha} \{ x_0^\alpha\}$ with spacing $\Delta x$.\todo[inline]{Perhaps prove this claim in the appendix.}
In other words
\begin{align}
	\begin{split}
		 \Pr(\hat{x}_0, x_0, k, s) G_{\sigma_v}( \hat{v}_0 - s X_k(x_0) ) = \\
		\qquad \left( \sum_{\alpha} c_{k,s,\alpha} \delta( x_0 - x_0^\alpha ) \right) + \varepsilon_0(x_0)
	\end{split}
	\label{eq:approximation 1}
\end{align}
for constants
\begin{align}
	c_{k,s,\alpha} =  \left. \left[ \Pr(\hat{x}_0, x_0, k, s) G_{\sigma_v}( \hat{v}_0 - s X_k(x_0) )  \Delta x^2 \right] \right|_{x_0 = x_0^\alpha} \label{eq:constants}
\end{align}
and error of magnitude $\| \varepsilon_0 \|_{L^1} \sim \mathcal{O}( \Delta x)$ with respect to the $L^1$-norm in $x_0$.
The coefficients, $c_{k,s,\alpha}$, can be computed efficiently as product of the posteriors appearing in the PGM.
Substitution of \eqref{eq:approximation 1} into the final line of \eqref{eq:push forward} yields
\begin{align*}
	\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s) = \sum_\alpha c_{k,s,\alpha} \delta \left( \check{x}_t - \Phi_{k,s}( x_0^\alpha) \right) + \varepsilon_t( \check{x}_t)
\end{align*}
where $\varepsilon_t( \check{x}_t) = \int \delta\left( \check{x}_t - \Phi_{k,s}^{t}( x_0) \right)  \varepsilon_0(x_0) dx_0$.
The first term is computable by flowing the points of the grid, $x_0^\alpha$, by the evolution of the vector field $s X_k$.
The second term, $\varepsilon_t$, may be viewed as an error term.
In fact, this method of approximating $\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s)$ as a sum of Dirac-deltas is adaptive, in that the error term does not grow in total mass.

\begin{thm} \label{thm:error}
	The error term, $\varepsilon_t$, is of size $\mathcal{O}( \Delta x)$ in the $L^1$-norm, for fixed $k,s,\hat{x}_0$, and $\hat{v}_0$.
	Moreover, the magnitude is constant in time.
\end{thm}
\begin{proof}
	To declutter notation, let us temporarily denote $\Phi_{k,s}^t$ by $\Phi$.
	We observe
\begin{align*}
	\| \varepsilon_t \|_{L^1} &= \int \left| \int \delta( \check{x}_t - \Phi(x_0) ) \varepsilon_0(x_0) dx_0 \right| d\check{x}_t \\
	&= \int \det( \left. D\Phi \right|_{\Phi^{-1}( \check{x}_t) }) |\varepsilon_{0}( \Phi^{-1}( \check{x}_t )) | d\check{x}_t \\
	&= \int | \varepsilon_0( u) | du = \| \varepsilon_0 \|_{L^1}
\end{align*}
As $\varepsilon_0$ is of magnitude $\mathcal{O}( \Delta x)$ the result follows.
\end{proof}

As the Gaussian convolution of a Dirac-delta distribution is a Gaussian distribution, the following corollary is nearly immediate.
\begin{cor} \label{cor:error}
	Let $G_{\sigma}(x-\mu)$ denote the probability density of a bivariate normal distribution of standard deviation $\sigma$ and mean $\mu$.
	Then the density
	\begin{align}
		\sum_\alpha c_{k,s,\alpha} G_{\kappa t}( x_t - \Phi_{k,s}^t( x_0^{\alpha}) ) \label{eq:approximation 2}
	\end{align}
	is an approximation of $\Pr( x_t, k, s, \hat{x}_0, \hat{v}_0)$
	with a constant in time error bound of magnitude $\mathcal{O}( \Delta x)$.
\end{cor}
\begin{proof}
	Recall that $\Pr( x_t, k, s, \hat{x}_0, \hat{v}_0)$ is related to $\Pr( \check{x}_t, k,s,\hat{x}_0, \hat{v}_0)$ by convolving the latter density in the variable $\check{x}_t$ with a Gaussian kernel of variance $\kappa t$.
	That is to say
	\begin{align*}
		\Pr(x_t, k, s, \hat{x}_0, \hat{v}_0) = \int G_{\kappa t}( x_t - \check{x}_t) \Pr( \check{x}_t, k,s,\hat{x}_0, \hat{v}_0) d\check{x}_t \\
	\end{align*}
	Substitution of \eqref{eq:approximation 1} yields
	\begin{align*}
		\Pr(x_t, k, s, \hat{x}_0, \hat{v}_0) = \sum_\alpha c_{\alpha} G_{\kappa t}( x_t - \Phi_{k,s}^t( x_0^{\alpha}) ) + (G_{\kappa t} * \varepsilon_t )
	\end{align*}
	Gaussian convolution preserves the $L^1$-norm of a density.
	Therefore $\| G_{\kappa t} * \varepsilon_t \|_{L^1} = \| \varepsilon_t \|_{L^1} \sim \mathcal{O}(\Delta x)$, which is also constant in time by Theorem \ref{thm:error}.
\end{proof}

Corollary \ref{cor:error} justifies using \eqref{eq:approximation 2} as an approximation of $\Pr( x_t, k,s,\hat{x}_0, \hat{v}_0)$.
So we've reduce the problem of computing $\rho_t(x_t)$ to the problem of computing the coefficient $c_{k,s,\alpha}$ and the points $\Phi_{k,s}^t(x_0^\alpha)$ for all $k,s$ and points $x_0^{\alpha} \in \Lambda$.
We can reduce this burden further by exploiting the following symmetry.
\begin{thm}
	$\Phi_{k,s}^t = \Phi_{k,1}^{st}$.
\end{thm}
\begin{proof}
	Say $x(t)$ satisfies the ordinary differential equation $x'(t) = sX_k(x(t))$ with the initial condition $x_0$.
	In other words, $x(t) = \Phi_{k,s}^{t}(x_0)$.
	Taking a derivative of $x(t/s)$, we see $\frac{d}{dt} (x(t/s)) = x'(t/s) /s = X_k(x(st))$.
	Therefore $x(t/s) = \Phi_{k,1}^{t}( x_0)$.
	Substitution of $t$ with $\tau = t/s$ yields $x(\tau) = \Phi_{k,1}^{s \tau} (x_0)$.
	As $x(\tau) = \Phi_{k,s}^{\tau}(x_0)$ as well, the result follows.
\end{proof}

Thus, computation of $\Phi_{k,s}^t( x_0^{\alpha})$ boils down to computing $\Phi_{k,1}^t(x_0^{\alpha})$.

At this point, we may summarize the ingredient to compute an approximation of $\Pr( x_t ,k,s \mid \hat{x}_0, \hat{v}_0 )$ in two parts
\begin{enumerate}
	\item Compute the constants $c_{\alpha}$ from \eqref{eq:constants}.
	\item Compute $\Phi_{k,1}^t(x_0^{\alpha})$ for each $k$ and each point $x_0^{\alpha}$ in the grid over a time-interval $[-T,T]$.
\end{enumerate}
Each of these pieces may be computed efficiently, and the full computation is embarrassingly parallel.
For example, for fixed $k$ and $\alpha$, the computation of $\Phi_{k,1}^t(x_0^{\alpha})$ on the interval $[-T,T]$ take $\mathcal{O}(T)$ time using a
an explicit finite difference scheme, and computation for each $(k,\alpha)$ may be performed in parallel with another such pair.
Moreover, computation $c_{k,s,\alpha}$ is embarrassingly parallel in with respect to all triples $(k,s,\alpha)$.
If the posteriors of our PGM consist solely of elementary functions such as Gaussians and polynomials, then computation of all coefficients $c_{k,s,\alpha}$
can be made virtually instantaneous given enough processors, as would be the case with a sufficiently powerful graphics processing unit.
More precisely, the full computation of our approximation of $\rho_t(x_t)$ would take $\mathcal{O}( T n A / N )$ time given $N$ processing units
where $A = | \cup_\alpha \{ x_0^\alpha\} |$ is the size of the mesh and $n$ is the number of vector fields.


%  Describe how $\Pr(x \mid k)$, the director-fields, and $\sigma_x$ are learned without using math.
%  Math will be relegated to the appendix.
%  
%  NOTE:  Learning $\kappa$.
%  \begin{enumerate}
%  	\item Learn vector-fields
%	\item Generate approximate curves for each v.f.
%	\item Compute $\kappa_k$ of best fit for each v.f.
%	\item $\kappa = \min_k \{ \kappa_1,\dots,\kappa_n\}$.
%  \end{enumerate}
  
\section{Implementation and Experimental results} \label{sec:implementation}
  Now that the model has been described, we can discuss a way, but certainly not the only way, that one can fit parameters of the model to a data set.
  For the purpose of demonstration, we will use the Stanford Drone Dataset \cite{StanfordDroneData}.
  More generally, we will assume that for a fixed scene we have a database of previously observed trajectories $\{ \hat{x}^1, \dots, \hat{x}^N\}$.
  From this data we will tune the parameters of the model appropriately.
  The parameters of the model which must be chosen or learned are
  \begin{itemize}
  	\item the vector-fields $\{ X_k\}_{k=1}^{n}$,
	\item the posteriors $\Pr(x \mid k,s)$ for $k=1,\dots,m$ and $s \in \mathbb{R}$,
	\item the posterior $\Pr(x \mid lin)$,
	\item the unconditioned probabilities $\Pr(f)$ for $f \in F$,
	\item the standard deviations of the measurement $\sigma_x$ and $\sigma_v$,
	\item and the blurring parameter $\kappa$.
  \end{itemize}
  
  \subsection{Learning the vector fields}
  Before we can even begin to learn vector-fields, we must learn the number of such vector-fields we have.
  To do this we use a simple clustering algorithm on the trajectories, to categorize them into groups.
  In principal, any clustering algorithm could accomplish this.
  For our algorithm we use the start and end point for each trajectory to obtain a point in $\mathbb{R}^4$.
  We then cluster in $\mathbb{R}^4$ using Affinity propagation.\todo{hoj:There is more to say here}
  This clustering of the end-points induces a clustering of the trajectories.
  So we obtain clusters $S_1, \dots, S_n$ consisting of trajectories from our data set, as well as a set of unclassified trajectories, $S_0$.
  
  For each set $S_k$ we may learn a vector-field which is approximately compatible with that set.
  We'd like to only consider vector-fields who's vectors have unit magnitude because we observe many of the trajectories in the data appear to have a roughly constant speed.
  Therefore we assume the vector-field takes the form $X_k(x) = \left( \cos( \Theta_k(x) ) , \sin(\Theta_k(x)) \right)$ for some scalar function $\Theta_k(x)$.
  Learning the vector-fields then boils down to learning the scalar function $\Theta_k$.
  We will assume $\Theta_k$ takes the form
  \begin{align*}
  	\Theta_k(x) = \sum_{\alpha} \theta_{k,\alpha} L_{\alpha}(x)
  \end{align*}
  for some collection of coefficients, $\theta_{k,\alpha}$, and a fixed collection of basis functions, $L_{\alpha}$.
  In our case, we've chosen $L_{\alpha}$ to be a set of low degree Legendre polynomials.
  Learning $\Theta_k$ can be obtained by looking at all the velocities observed in the cluster, $S_k$.
  These velocities may be obtained by a low order finite difference formula.
  Upon normalizing the velocities, we obtain a unit-length velocity vectors, $v_{i,k}$, anchored at each point, $x_{i,k}$, of $S_k$.
  We can learn $\Theta_k$ by defining the cost-function
  \begin{align*}
  	C[ \Theta_k] = \sum_i \langle v_{i,k} , ( \cos(\Theta_k( x_{i,k}) , \sin( \Theta_k( x_{i,k} ) ) \rangle
  \end{align*}
  which penalizes $\Theta_k$ for producing a misalignment with the observed velocities at the observed points of $S_k$.
  When $\Theta_{k}$ includes high order polynomials (e.g. beyond 5th order), we should also include a regularization term to bias the minimizes towards smoother outputs.
  Using the $H^1$-norm times a fixed scalar would suffice.
  
  
  \subsection{Learning the posteriors}
  We'd like to compute $\Pr( x_0 \mid k,s)$ for each cluster $k=1,\dots,n$ and each speed $s \in \mathbb{R}$.
  We will make the modeling assumption that $x_0$ is independent of $s$ given $k$, i.e. $\Pr( x_0 \mid k,s) = \Pr(x_0 \mid k)$.
  Additionally, we will assume that $s$ and $k$ are independent.
  This means that we only need to learn $\Pr( x_0 \mid k)$, $\Pr(k)$, and $\Pr(s)$.
  
  We will let $\Pr(k) = (n+1)^{-1}$ and $\Pr(s) \sim \mathcal{U}( [-s_{\max}, s_{\max} ] )$
  where $s_{\max}>0$ is the largest observed speed in the dataset.  This implies that $\Pr(lin) = (n+1)^{-1}$ as well.
  Other reasonable choices (such as $\Pr(k) \propto | S_k|$) could work, but we've chosen to be more conservative in this paper.
  
  In order to learn $\Pr( x_0 \mid k)$ we will assume that it's logarithm may be approximated by a low dimensional subspace of functions on $\mathbb{R}^2$.
  That is to say, for each $k$ we will assume $\Pr( x_0 \mid k) = \frac{1}{Z_k} \exp( - V_k(x_0) )$ and $V_k$ is a function who's constant term is $0$ and is given by
  \begin{align*}
  	V_k(x_0; \mathbf{c} ) := \sum_{|\alpha|< d} c_{\alpha} L_{\alpha}( x_0)
  \end{align*}
  for a collection of basis functions, $L_{\alpha}$ and coefficients $\mathbf{c} = \{ c_{\alpha} \}_{|\alpha| < d}$.
  We chose our basis functions to be the collection of tensor products from the first $6$ Legendre polynomials, normalized to the size of the domain.
  Then, one may fit the coefficients $c_{\alpha}$ to the data by using a log-likelihood criterion.
  The resulting (convex) optimization problem takes the form
  \begin{align*}
  	\mathbf{c}^* = \inf_{ |\mathbf{c}| } \sum_{x \in S_k} V_k( x_0; \mathbf{c})
  \end{align*}
  Where the norm on $\mathbf{c}$ is a sup-norm.
  We can also bias this optimization towards more regular functions by adding a penalty to the cost function.
  
  Finally, we let $\Pr( x_0 \mid lin) \sim \mathcal{U}(D)$.
  
  \subsection{Learning the variance parameters}
  We will assume that the true trajectory of an agent is fairly smooth compared to the noisy output of our measurement device.
  This justifies smoothing the trajectories, and using the difference between the smoothed signals and the raw data to learn the variance $\sigma_x$.
  To obtain the results in this paper we have used a moving average of $4$ time steps (this is $0.13$ seconds in realtime).
  We set $\sigma_v = 2 \sigma_x / \Delta t$ where $\Delta t > 0$ is the time-step size.  This choice is justified from the our use of finite difference's to estimate velocity.
  In particular, if velocity is approximated via finite differencing as $v(t) \approx (x(t+h) - x(t))\,\Delta t^{-1} + \mathcal{O}(h)$
  and the measurements are corrupted by Gaussian noise, then the measurement $\hat{v}(t)$ is related to $v(t)$ by Gaussian noise with roughly the same standard deviation as $(x(t+h) - x(t))\,\Delta t^{-1}$.
  
  Finally, we must learn $\kappa$, the parameter which blurs the our motion model.
  We've taken an ad hoc approach in this paper, although more intelligent and theoretically sound alternatives likely exist.
  For each curve in $S_k$ we create a synthetic curve using the initial position and speed and integrating the corresponding vector-field, $s\, X_k$.
  So for each curve, $x_i(t)$, of $S_k$, we have a synthesized curve $x_{i,synth}(t)$ as well.
  We then measure the standard deviation of $(x_i(t) - x_{i,synth}(t)) / t$ over $i$ and at few time, $t \in \{ 0, 100, 200 \}$ in order to obtain $\kappa$.
  
 \subsection{ Precision, accuracy, etc.}


\section{Conclusion} 
\label{sec:conclusion}

The conclusion goes here.

\section*{Acknowledgments}
Thanks to Kris Kitani

\appendix
\subsection{Inverse Optimal Control} \label{app:ioc}
One of the valuable aspect of the motion model of \cite{Kitani2012} was that the trajectories were solutions of optimal control problems.
This is a desirable property for a motion model of pedestrians/cyclists/vehicles in that it seems reasonable to assume that we all move through the world with an intent to get somewhere.
This framework where one determines an optimal control problem from trajectories (as opposed to solving for trajectories of an optimal control problem) was dubbed \emph{inverse optimal control} (IOC).
In this optional subsection, we illustrate how solutions of \ref{eq:ode} can fit within the IOC framework.

\begin{thm}
	Let $X$ be a vector-field such that $\| X(x) \|_2 = 1$ for all $x \in \mathbb{R}^2$.
Then, for each initial condition $x_0 \in \mathbb{R}^2$, there exists a neighborhood $U$, a Riemannian metric, $g$, and a cost function, $f$, 
such that solutions of \eqref{eq:ode} are also solutions of the optimal control problem
\begin{align}
	p^* = \inf_{ \| v_t \|_g = s } \int_0^T f( x_t) dt \label{eq:IOC}
\end{align}
where $v_t = \frac{d x_t}{dt}$, $\| \cdot \|_g$ is the norm with respect to $g$ and the infimum is taken over all differentiable curves in $U$ which originate from $x_0$.
\end{thm}

\begin{proof}
	By rescaling time, we may let $s$ be any positive real number.
	Therefore, without loss of generality, we will seek an $f$ and $g$ such that $s=1$.
	In this case a solution of \eqref{eq:IOC} is generated by the vector-field $X = \frac{\nabla f}{ \| \nabla f\|}$ where $\nabla$ is the Riemannian gradient with respect to some metric (possibly non-Euclidean).
	Therefore, our goal is to illustrate that there exists a metric $g$ and a function $f$ such that the given $X$ is given by $\frac{\nabla f}{ \| \nabla f\|}$.

	Because $\| X \| = 1$ globally, it has no fixed points.
	From the flow-box theorem \cite[Theorem 4.1.14]{MTA} we can assert that for any open set, $U \subset \mathbb{R}^2$ there exists a local diffeomorphism which transforms $X_k$ into a flat vector-field.
	Mathematically, this asserts the existence of a map $\Phi : U \to V \subset \mathbb{R}^2$ such that the push-forward of $X$, which we will denote by $\tilde{X}$, and given by
	\begin{align*}
		\tilde{X}(\tilde{x}) = \Phi_* X(\tilde{x}) := \left. D\Phi \right|_{\Phi^{-1}(\tilde{x}) } \cdot X(  \Phi^{-1}(\tilde{x}) ),
	\end{align*}
	is just the flat vector field $(1,0)$ for all $x \in U$.
	We could view the coordinate function $\tilde{f}(x) = x^0$ as a cost function on $V$,
	and we may set $g_V$ to be equal to the standard flat metric on $V$ inherited from $\mathbb{R}^2$.
	In this case we observe that $\tilde{X}$ generates solutions to the optimization problem
	\begin{align*}
		\tilde{p}^* = \inf_{ \| \tilde{v}_t \|_{g_V} \leq 1} = \int_0^T \tilde{f}( \tilde{x}_t ) dt
	\end{align*}
	By a change of variables, it follows that the original vector field, $X$, then solves the optimization problem \eqref{eq:IOC}
	where $g = \Phi^* g_V$ is the pull-back metric, and $f = \Phi^* \tilde{f}$ is the pull-back of $\tilde{f}$.
\end{proof}


%% Use plainnat to work nicely with natbib. 

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}


