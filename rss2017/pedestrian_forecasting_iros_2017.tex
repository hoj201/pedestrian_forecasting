\documentclass{IEEEconf}
\usepackage{times}

%  For math environment 
\usepackage{amsmath,amssymb,amsthm}
\usepackage{caption}
%  For todo notes
\usepackage{todonotes}
%  For drawing Bayesian networks
\usepackage{tikz}
\usetikzlibrary{arrows,positioning}
\usepackage{tikz-cd}
\usepackage{comment}
\usepackage{color}  % For Highlighting

%  For theorems, etc
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}

% numbers option provides compact numerical references in the text. 
%\usepackage[numbers]{natbib}
%\usepackage{multicol}
\usepackage[bookmarks=true]{hyperref}
\newcommand{\Ram}[1]{\textcolor{red}{#1}}

% Custom commands
\newcommand{\pder}[2]{\ensuremath{\frac{\partial #1}{\partial #2}}}


\begin{document}

% paper title
\title{Real-Time Probabilistic Pedestrian Forecasting}

% You will get a Paper-ID when submitting a pdf file to the conference system
\author{Henry O. Jacobs, Owen Hughes, Ram Vasudevan}


\maketitle

\begin{abstract}
That autonomous vehicles will come to dominate our streets is imminent.
This motivates the need for a real-time probabilistic forecasting algorithm for pedestrians, cyclists, and other agents,
as it forms a necessary step in assessing the risk (and therefore the cost) we should expect to incur.
In this paper, we present a novel approach to probabilistic forecasting for pedestrians based on weighted sums of ordinary differential equations.
The resulting algorithm is embarrassingly parallel, and trained on historical trajectory information within a fixed scene.
When compared with MDP-based methods, our algorithm appears to be superior from the standpoint of precision and recall.
\end{abstract}

%\IEEEpeerreviewmaketitle

\section{Introduction}

Autonomous systems acting in human-centric environments should be able to anticipate the behavior of neighboring humans to ensure safe operation. 
Anticipating the future locations of individuals within a scene, for instance, is critical to synthesizing safe controllers for autonomous vehicles.
To aid during safe control design for such systems, a prediction algorithm must satisfy several important criteria.
First, since safety is paramount, the prediction algorithm should avoid misclassifying areas as unoccupied.
Second, the predictions must be generated at faster than real-time rates to ensure that they can be used within a control loop.
Finally, long-time horizon forecasts are preferable since they can make planning over long-time horizons feasible, which can reduce the conservativeness and aggressiveness of controllers \cite{}.

\todo[inline]{We should include a figure here showing what our algorithm looks like?}

This paper presents an algorithm for real-time, long-term prediction of pedestrian behavior which can subsequently be used by autonomous agents.

As depicted in Figure \ref{fig:}, this approach relies upon ... 
The presented approach significantly outperforms...

%First, since safety is paramount, generated predictions must avoid misclassifying areas as unoccupied even though humans are present. 
%Though this may unduly reduce the precision of the algorithm 

\subsection{Background}
Most forecasting algorithm are well characterized by the underlying evolution model they adopt.
Such models come in a variety flavors, and are adapted to the task at hand (e.g. crowd modeling \cite{Helbing1992} ).
This paper is focused on the construction of useful motion models for pedestrians that can aide the task of real-time forecasting for autonomous agents.
The simplest approach to forecasting with motion models forward integrates a Kalman filter \cite{kalman1960new} based upon the observed heading.
Over short time scales this method may perform well, but the resulting distribution devolves into a Gaussian mass over longer time scales.
This is a typical property of the extended Kalman filter and Kalman filter with deterministic nonlinear drift \cite{Schneider2013}.
In particular, such models are less useful for forecasts beyond $2$ seconds in the future, especially when a pedestrian turns.
Nonetheless, these stochastic linear models serve as a reasonable default in the absence of any contextual knowledge.
For example, \cite{Kooji2014} uses a motion model of this variety, parametrized by latent variables, such as the pedestrian's awareness of nearby vehicles, to predict when and how a pedestrian may cross a street without leveraging any environmental context.

More sophisticated models that attempt to leverage environmental data include inverse optimal control (IOC) based models \cite{Ziebart2008,Ziebart2009,Kitani2012,Karasev2016}.
These IOC models have the often desirable property of attributing intention and goal-seeking behavior to the agents.
For example, \cite{Kitani2012} extracted a Markov Decision Process (MDP) evolving on a finite 2D lattice by training on a small collection of features and trajectories.
The resulting MDP is light-weight since it is parametrized by only a small collection of coefficients equal in number to that of the feature maps.
Moreover, given an initial and final state, the probability distribution of the pedestrian at intermediate states is computable using matrix multiplication.
The speed of this computation, makes the algorithm of \cite{Kitani2012} a reasonable baseline for comparison for the algorithm that is presented in this paper.

The approach presented by \cite{Kitani2012} has been generalized in a variety of ways.
For example, time-dependent information, such as traffic signals, are incorporated by \cite{Karasev2016}, by relaxing the Markov property and considering a switched Markov process.
Other generalizations by \cite{Karasev2016} include replacing the finite-state space with a continuous one, and using a Markov jump process in the motion model.
Unfortunately the desired posteriors are difficult to compute in closed form, and as a result a sampling based method: a Rao-Blackwellized particle filter~\cite{Doucet2000} is employed.
The resulting accuracy of such methods can only be known in a probabilistic sense in that the error bounds are themselves random variables.
Moreover, accuracy can come at a large computational expensive which is prohibitive during real-time computation.
%Speed and analytic error bounds were not a primary objective of \cite{Karasev2016}, and thus were not addressed in that publication.

%\todo[inline]{I could also mention \emph{Inferring ``Dark Matter'' and ``Dark Energy'' from Videos}.  It is another IOC model, and is cited in \cite{Ballan2016}.  However, this paper is awful, and I don't even know how to describe it if we presumable wanted to describe the results.  Here is an actual sentence from the results section of the paper: \emph{``The trajectory prediction (NLL and MHD) is more accurate is constrained scene (1 2) than free scenes (3 4).''}.}

One limitation of IOC models occurs when the initial and final conditions are separated across a complex domains, analogous to the notion of conjugate points in optimal control.
\todo[inline]{What is the limitation?}
This can occur when agents make sharp turns due to intermediate goals on the way toward reaching their final destination.
To address this, \cite{Ballan2016} adopted an empiricists approach, computing ``turning maps'' and attempting to infer how agents behave in a given patch based on it's feature and the behavior of previous agents on similar patches.
Similar to \cite{Karasev2016}, the motion model was a Markov jump process and the relevant posteriors were approximated using sample based techniques.
%Again, the same criticisms in regards to speed an accuracy lodged at \cite{Karasev2016} can also be lodged at \cite{Ballan2016}, and again, we should note that speed/high accuracy were not a priority there.
The objective of \cite{Ballan2016} was not only prediction, but the development of a motion model learned on one scene that could then subsequently be transferred to other scenes which required representations of ``objects'' in the scene that did not depend rigidly on the finitely many labels some engineer managed to think of in a late-night brainstorming session.
The algorithm should be able to infer how to behave near a roundabout by using prior knowledge of more fundamental building blocks like pavement, curbs, and asphalt.

Along similar lines to \cite{Ballan2016}, \cite{Walker2014} constructed an unsupervised approach towards forecasting.
As before, the motion model was a Markov jump process, and the training set was a collection unlabeled videos.
Unlike all the approaches mentioned thus far, the agents in \cite{Walker2014} were not manually specified.
They were learned by detecting which sort of patches of video were likely to move, and how.
The resulting predictions outperformed \cite{Kitani2012} when comparing the most likely path with the ground truth using the mean Hausdorff distance.
As in all methods mentioned thus far, computational speed and accuracy of any predicted posteriors were not a concern of \cite{Walker2014}, so no such results were reported.
However, since the motion model was a Markov jump process which required the application of a sample based technique, we should expect the same painful trade-off between error and speed to occur as in \cite{Karasev2016} and \cite{Ballan2016}.

\subsection{Contributions}

The primary contributions of this paper are:
\begin{itemize}
	\item We provide a computationally expedient and accurate motion model for pedestrian forecasting.
	\item We evaluate the precision, accuracy, and recall of our model
	\item We compare our performance to that of a linear predictor and the MDP model of \cite{Kitani2012}, both in terms of precision and recall as well as computation time.
\end{itemize}

\todo[inline]{I feel like your first contribution should be broken into two separate contributions: first you propose an accurate motion model. Second you describe a computationally expedient method for pedestrian forecasting. Third you prove hard bounds on how accurate your prediction is. I also don't think the second and two things are contributions they are just things that illustrate that the aforementioned contributions are actually useful contributions.}

\todo[inline]{We also seem to focus our attention on image based methods where we work in 2D...is this typical? If so that may be worth mentioning early on...}

We should note that there are a number of things that we do not do, that similar papers to ours typically include (notably \cite{Ballan2016,Karasev2016}).
For example, we do not concern ourselves with detection and tracking. 
Nor do we concern ourselves with updating our prediction as new data comes along.
\todo[inline]{You may want to mention that this is a straightforward extension but you don't consider it here}.
Such questions are important, but beyond the scope of this paper, which concerns the underlying dynamic model.
Papers such as \cite{Ballan2016,Karasev2016} pose a more comprehensive approach to pedestrian forecasting, where the motion model is a choice to be made.
This paper presents one such choice.
\todo[inline]{I don't understand what you are trying to say in the previous three sentences. As I understand it our goal is construct a model of the motion, a method to efficiently compute the future state and provide hard bounds that can then be used during autonomous vehicle control. May be I am misunderstanding it, but you make it seem like those two previous approaches are agnostic to the model and we on the other hand are very focused on the model. I'd argue the opposite is true.}.
It is our opinion, that the motion model for many practical applications of forecasting must run in real-time and that any relevant approximations ought to be equipped with hard error bounds to ensure safety.

The rest of the paper is organized as follows:
\begin{itemize}
	\item We describe our motion model as a Bayesian network (\S \ref{sec:model}).
	\item We then describe how to compute probability densities for an agent's position efficiently (\S \ref{sec:efficient}).
	\item Finally, we demonstrate the model by training and testing it on the Stanford drone dataset (\S \ref{sec:implementation}). \todo[inline]{Have to cite the Stanford drone paper...}.
\end{itemize}

\section{Model}\label{sec:model}
This paper's goal is to generate a time-dependent probability density over $\mathbb{R}^2$, which predicts the true location of an agent in the future.
The input to the algorithm at runtime is a noisy measurement of position and velocity, $\hat{x}_0, \hat{v}_0 \in \mathbb{R}^2$.
If the (unknown) location of agent at time $t$ is given by $x_t \in \mathbb{R}^2$, then the distribution we seek is the posterior $\rho_t(x_t) := \Pr( x_t \mid \hat{x}_0, \hat{v}_0 )$.

To numerically compute $\rho_t$, we build a probabilistic graphical model.
Our model assumes we have noisy information about agents, and each agent moves with some intention through the world in a way that is roughly approximated by a model.
Our model can be divided into three parts:
\begin{enumerate}
	\item Reality: This is parametrized by the true position for all time, $x_t$, and the initial velocity of the agent $v_0$.
	\item Measurements:  This is represented by our sensor readings $\hat{x}_0$ and $\hat{v}_0$ and are independent of all other variables given the true initial position and velocity, $x_o, v_0$.
	\item Motion Model: This is represented by a trajectory $\check{x}_t$ and depends on a variety of other variables which are described below.
\end{enumerate}
We now elaborate on these three components, and relate them to one another.
Many of the choices we make are motivated by a balance between model quality and computational speed (see \S \ref{sec:efficient}).

\subsection{The Sensor Model}
At time $t=0$, we obtain a noisy reading of position, $\hat{x}_0 \in \mathbb{R}^2$.
We assume that given the true position, $x_0 \in \mathbb{R}^2$, that the measurement $\hat{x}_0$ is independent of all other variables \Ram{what other variables are there??} and the posterior $\Pr( \hat{x}_0 \mid x_0)$ is known.
%something easily computable, such as a Gaussian.
We assume a similar measurement model for the measured initial velocity $\hat{v}_0$.

\subsection{The Agent Model}
All agents are initialized within some rectangular region $D \subset \mathbb{R}^2$.
We denote the true position of an agent by $x_t$.
We should never expect to know $x_t$ and the nature of its evolution precisely, and any model should account for its own (inevitable) imprecision.
We do this by fitting a deterministic model to the data and then smoothing the results.
Specifically, our motion model consists of a modeled trajectory $\check{x}_t$, which is probabilistically related to the true position by $x_t$ via a known and easily computable posterior, $\Pr(x_t \mid \check{x}_t)$.

Once initialized, agents come in two flavors: linear and nonlinear.
The linear agent model evolves according to the equation $\check{x}_t = x_0 + t v_0$ and so we have the posterior:
\begin{align*}
	\Pr( \check{x}_t \mid x_0, v_0, lin) = \delta( \check{x}_t - x_0 - t v_0 ).
\end{align*}
\Ram{have to explain what $\delta$ is} We also assume the posteriors, $\Pr(x_0 \mid lin)$ and $\Pr( v_0 \mid lin, x_0)$ are known.
%simple expressions such as Gaussians or uniform distributions

If the agent is of nonlinear type, then we assume the dynamics take the form:
\begin{align}
	\frac{d \check{x}_t}{dt} = s \cdot X_k(\check{x}_t) \label{eq:ode}
\end{align}
where $X_k$ is a vector-field from a finite collection $\{X_1, \dots, X_n\}$, and $s \in \mathbb{R}$. \Ram{probably will have to explain what a vector field is...}.
More specifically, we assume that each $X_k$ has the property that $\| X_k(x) \| = 1$ for all $x \in D$.
This property ensures that speed is constant in time, and it has the further advantage of being the (local) generator
of solutions to an optimal navigation problem (see Appendix \ref{app:ioc}).
As we describe in \S \ref{sec:implementation}, the stationary vector-fields $X_1,\dots,X_n$ are learned from the dataset.

It is assumed that $k$ and $s$ are both constant in time, so that $\check{x}_t$ is determined from the triple $(x_0,k,s)$ by integrating \eqref{eq:ode} with the initial condition $x_0$.
In other words, we have the posterior
\begin{align}
	\Pr( \check{x}_t \mid x_0 , k , s) = \delta( \check{x}_t - \Phi^{t}_{k,s}( x_0) ) \label{eq:x_check | ksx}
\end{align}
where $\Phi^{t}_{k,s}$ is the flow-map of the vector field $s \,X_k$ up to time $t$ \Ram{will probably have to explain what flow map is or at least cite something...}.
Note the variables $k,s$ and $x_0$ determine $v_0$.
Thus we have the posterior
\begin{align}
	\Pr( v_0 \mid k, s, x_0) = \delta( v_0 -s X_k( x_0) ). \label{eq:v | ksx}
\end{align}
In summary, the agent models are parametrized by the set
\begin{align}
	\mathcal{M} = \{ lin \} \cup \left( \mathbb{R} \times \{ 1 , \dots, n \} \right) \label{eq:models}
\end{align}
and each flavor determines the type of motion we should expect from the agent model.

\subsection{The Full Model}
Concatenating the measurement model with our motion models yields the Bayesian network, where $M \in \mathcal{M}$ denotes the model of the agent:
\begin{align}
\begin{tikzpicture}[thick, var/.style={circle,draw,thin,rounded corners,shade,top color=blue!50,minimum size = 4mm}]
	\node[var] (M) {$M$};
	\node[var] (x)[right=of M] {$x_0$};
	\node[var] (v)[below=of x] {$v_0$};
	\node[var] (x_hat) [right=of x] {$\hat{x}_0$};
	\node[var] (v_hat) [right=of v] {$\hat{v}_0$};
	\node[var] (x_check_t) [left=of v] {$\check{x}_t$};
	\node[var] (x_t) [left=of x_check_t] {$x_t$};
	\draw[->] (M) to (x);
	\draw[->] (M) to (v);
	\draw[->] (M) to (x_check_t);
	\draw[->] (x) to (x_hat);
	\draw[->] (x) to (x_check_t);
	\draw[->] (x) to (v);
	\draw[->] (v) to (x_check_t);
	\draw[->] (v) to (v_hat);
	\draw[->] (x_check_t) to (x_t); 
\end{tikzpicture}.\label{eq:pgm}
\end{align}
We may use this Bayesian network to compute $\rho_t$ efficiently.
In particular
\begin{align}
	\rho_t(x_t ) &:= \Pr( x_t \mid \hat{x}_0, \hat{v}_0 ) \\
	&= \left( \sum_{k} \int \Pr( x_t, k , s  \mid \hat{x}_0, \hat{v}_0 ) ds \right) \\
	&\quad + \Pr( x_t, lin \mid \hat{x}_0, \hat{v}_0 ). \label{eq:decomposition}
\end{align}
The final term $\Pr( x_t, lin \mid \hat{x}_0, \hat{v}_0 )$ is expressible in terms of the error function \Ram{what error function?}, and would pose a negligible burden in terms of numerical computation.
The primary computational burden derives from computing $\sum_{k} \int \Pr( x_t, k , s  \mid \hat{x}_0, \hat{v}_0 ) ds$.

\section{Efficient Probability Propagation} \label{sec:efficient}
As mentioned, many of the modeling choices were born out of a balance between accuracy and real-time computability.
One of the major modeling choices, that agents move approximately according to a small number of ODEs, is the most prominent such choice.
This section details how this modeling choice can be leveraged to compute $\rho$ quickly and accurately.
In particular, we illustrate how to compute an accurate approximation of the the posterior $\Pr( x_t, k,s \mid \hat{x}_0, \hat{v}_0)$ by integrating the vector-fields $X_1, \dots, X_n$ on a fixed grid.

To begin, from \eqref{eq:pgm}  notice that
\begin{align}
	&\Pr( x_t, k,s,\mid \hat{x}_0, \hat{v}_0) \propto \Pr( x_t, k,s,\hat{x}_0, \hat{v}_0) \\
	&= \int \Pr( x_t, \check{x}_t , \hat{x}_0, \hat{v}_0, k,s) d\check{x}_t \\
	&= \int \Pr( x_t \mid \check{x}_t ) \Pr(\check{x}_t , \hat{x}_0, \hat{v}_0, k,s) d\check{x}_t \label{eq:convolve}
\end{align}
We see from the last line that $\Pr( x_t, k,s,\mid \hat{x}_0, \hat{v}_0)$ is proportional to a convolution of the joint distribution $\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s)$.
Assuming, for the moment, that such a convolution can be performed efficiently, we focus on computation of $\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s)$.

Again, \eqref{eq:pgm} implies  \Ram{this next set of equations seem broken during typesetting}
\begin{align}
	&\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s) = \int \Pr( \check{x}_t , x_0, \hat{x}_0, v_0, \hat{v}_0, k,s) dx_0 \, dv_0 \\
		&=  \int \Pr( \check{x}_t \mid  x_0, k,s, v_0) \Pr( \hat{v}_0 \mid v_0) \Pr( v_0 \mid k,s,x_0) \\
		& \hspace{20ex} \Pr(\hat{x}_0, x_0, k, s) dx_0 \, dv_0 \\
\end{align}
Substitution of \eqref{eq:x_check | ksx} and \eqref{eq:v | ksx} yields  \Ram{this next set of equations seem broken during typesetting}
\begin{align}
		&= \int \delta\left( \check{x}_t - \Phi_{k,s}^{t}( x_0) \right) \delta\left( v_0 - s X_k (x_0) \right) \\
		&\hspace{20ex}\Pr( \hat{v}_0 \mid v_0) \Pr(\hat{x}_0, x_0,k, s) dx_0\, dv_0
\end{align}
Carrying out the integration over $v_0$ we observe
\begin{align}
\begin{split}
	&\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s) = \\
	&\int \delta\left( \check{x}_t - \Phi_{k,s}^{t}( x_0) \right) \Pr(\hat{x}_0, x_0, k, s) \Psi(\hat{v}_0 ;k,s,x_0) dx_0
\end{split}
\label{eq:push forward}
\end{align}
 Where $\Psi( v_0 ;k,s,x_0) := \left. \Pr( \hat{v}_0 \mid v_0) \right|_{v_0 = s X_k(x_0)}$.
 Assuming the density $\Pr(\hat{x}_0, x_0, k, s) \Psi( \hat{v}_0 ; k, s, x_0)$ is of bounded variation in the variable $x_0$ (with all other variables held fixed),
 we may approximate it as a sum of weighted Dirac delta's supported on a regular grid, $\Gamma = \cup_{\alpha} \{ x_0^\alpha\}$ with spacing given by $\Delta x$ \cite{Rudin1991}.
In other words
\begin{align}
	\begin{split}
		&\Pr(\hat{x}_0, x_0, k, s) \Psi( \hat{v}_0 ; k, s, x_0 ) = \\
		&\qquad \left( \sum_{\alpha} c_{k,s,\alpha} \delta( x_0 - x_0^\alpha ) \right) + \varepsilon_0(x_0)
	\end{split}
	\label{eq:approximation 1}
\end{align}
for constants
\begin{align}
	c_{k,s,\alpha} =  \left. \left[ \Pr(\hat{x}_0, x_0, k, s) \Psi( \hat{v}_0 \mid k,s,x_0 )  | \Delta x | \right] \right|_{x_0 = x_0^\alpha} \label{eq:constants}
\end{align}
and error of magnitude $\| \varepsilon_0 \|_{L^1} \sim \mathcal{O}( | \Delta x | )$ with respect to the $L^1$-norm in $x_0$.
The coefficients, $c_{k,s,\alpha}$, can be computed efficiently as product of the posteriors appearing in the PGM \Ram{this acronym was never defined...}.
Substitution of \eqref{eq:approximation 1} into the final line of \eqref{eq:push forward} yields:
\begin{align*}
	\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s) = \sum_\alpha c_{k,s,\alpha} \delta \left( \check{x}_t - \Phi_{k,s}( x_0^\alpha) \right) + \varepsilon_t( \check{x}_t)
\end{align*}
where $\varepsilon_t( \check{x}_t) = \int \delta\left( \check{x}_t - \Phi_{k,s}^{t}( x_0) \right)  \varepsilon_0(x_0) dx_0$.
The first term is computable by flowing the points of the grid, $x_0^\alpha$, by the evolution of the vector field $s X_k$.
The second term, $\varepsilon_t$, may be viewed as an error term.
In fact, this method of approximating $\Pr( \check{x}_t , \hat{x}_0, \hat{v}_0, k,s)$ as a sum of Dirac-deltas is adaptive, in that the error term does not grow in total mass:

\begin{thm} \label{thm:error}
	The error term, $\varepsilon_t$, is of size $\mathcal{O}( \Delta x)$ in the $L^1$-norm, for fixed $k,s,\hat{x}_0$, and $\hat{v}_0$.
	Moreover, the magnitude is constant in time.
\end{thm}
\begin{proof}
	To declutter notation, let us temporarily denote $\Phi_{k,s}^t$ by $\Phi$.
	We observe
\begin{align*}
	\| \varepsilon_t \|_{L^1} &= \int \left| \int \delta( \check{x}_t - \Phi(x_0) ) \varepsilon_0(x_0) dx_0 \right| d\check{x}_t \\
	&= \int \det( \left. D\Phi \right|_{\Phi^{-1}( \check{x}_t) }) |\varepsilon_{0}( \Phi^{-1}( \check{x}_t )) | d\check{x}_t \\
	&= \int | \varepsilon_0( u) | du = \| \varepsilon_0 \|_{L^1}
\end{align*}
As $\varepsilon_0$ is of magnitude $\mathcal{O}( \Delta x)$ the result follows.
\end{proof}

While this allows us to compute posteriors over the output of our models, $\check{x}_t$.  We ultimately care about densities over the true position.
The following corollary of Theorem \ref{thm:error} addresses this:
\begin{cor} \label{cor:error}
	The density
	\begin{align}
		\sum_\alpha c_{k,s,\alpha} \left. \Pr( x_t \mid \check{x}_t ) \right|_{ \check{x}_t = \Phi_{k,s}^t( x_0^\alpha) } \label{eq:approximation 2}
	\end{align}
	is an approximation of $\Pr( x_t, k, s, \hat{x}_0, \hat{v}_0)$ with a constant in time error bound of magnitude $\mathcal{O}( |\Delta x| )$.
\end{cor}
\begin{proof}
	By \eqref{eq:convolve}
	\begin{align*}
		\Pr(x_t, k, s, \hat{x}_0, \hat{v}_0) = \int \Pr( x_t \mid \check{x}_t ) \Pr( \check{x}_t, k,s,\hat{x}_0, \hat{v}_0) d\check{x}_t \\
	\end{align*}
	Substitution of \eqref{eq:approximation 1} yields
	\begin{align*}
		&\Pr(x_t, k, s, \hat{x}_0, \hat{v}_0) \\
		&\qquad = \sum_\alpha c_{k,s,\alpha} \left. \Pr( x_t \mid \check{x}_t ) \right|_{ \check{x}_t = \Phi_{k,s}^t( x_0^\alpha) } + \tilde{\varepsilon}_t(x_t)
	\end{align*}
	where the error term is
	\begin{align*}
		\tilde{\varepsilon}_t(x_t) = \int \Pr( x_t \mid \check{x}_t) \varepsilon_t( \check{x}_t) d \check{x}_t
	\end{align*}
	and $\varepsilon_t$ is the error term of \eqref{eq:approximation 1}.
	We see that the $L^1$-norm of $\tilde{\varepsilon}_t$ is 
	\begin{align*}
		\| \tilde{\varepsilon}_t \|_{L^1} &= \int \left| \int \Pr( x_t \mid \check{x}_t) \varepsilon_t( \check{x}_t) d \check{x}_t \right| dx_t \\
			&\leq \int \Pr( x_t \mid \check{x}_t ) | \varepsilon_t |( \check{x}_t) d\check{x}_t \, dx_t \\
	\end{align*}
	Implementing the integration over $x_t$ first yeilds
	\begin{align*}
		\| \tilde{\varepsilon}_t \|_{L^1} \leq \int | \varepsilon_t |( \check{x}_t) d\check{x}_t =: \| \varepsilon_t \|_{L^1}
	\end{align*}
	which is $\mathcal{O}( | \Delta x | )$ by Theorem \ref{thm:error}.
\end{proof}

Corollary \ref{cor:error} justifies using \eqref{eq:approximation 2} as an approximation of $\Pr( x_t, k,s,\hat{x}_0, \hat{v}_0)$.
In particular, this reduces the problem of computing $\rho_t(x_t)$ to the problem of computing the coefficient $c_{k,s,\alpha}$ and the points $\Phi_{k,s}^t(x_0^\alpha)$ for all $k,s$ and points $x_0^{\alpha} \in \Lambda$.
We can reduce this burden further by exploiting the following symmetry:
\begin{thm} \label{thm:symmetry}
	$\Phi_{k,s}^t = \Phi_{k,1}^{st}$.
\end{thm}
\begin{proof}
	Say $x(t)$ satisfies the ordinary differential equation $x'(t) = sX_k(x(t))$ with the initial condition $x_0$.
	In other words, $x(t) = \Phi_{k,s}^{t}(x_0)$.
	Taking a derivative of $x(t/s)$, we see $\frac{d}{dt} (x(t/s)) = x'(t/s) /s = X_k(x(st))$.
	Therefore $x(t/s) = \Phi_{k,1}^{t}( x_0)$.
	Substitution of $t$ with $\tau = t/s$ yields $x(\tau) = \Phi_{k,1}^{s \tau} (x_0)$.
	As $x(\tau) = \Phi_{k,s}^{\tau}(x_0)$ as well, the result follows.
\end{proof}
\noindent Thus, computation of $\Phi_{k,s}^t( x_0^{\alpha})$ for all $s$ and $t$ boils down to computing $\Phi_{k,1}^t(x_0^{\alpha})$ for all $t$.

At this point, we may summarize the steps needed to compute an accurate approximation of $\rho_t(x_t)$ \Ram{maybe you want to make this an algorithm, but putting it in an algorithm box}:
\begin{enumerate}
	\item Compute the constants $c_{k,s,\alpha}$ from \eqref{eq:constants}.
	\item Compute $\Phi_{k,1}^t(x_0^{\alpha})$ for each $k$ and each point $x_0^{\alpha}$ in the grid over a time-interval $[-T,T]$.
	\item Use Theorem \ref{thm:symmetry} so obtain $\Phi_{k,s}^t( x_0^\alpha)$ from $\Phi_{k,1}^t(x_0^{\alpha})$.
	\item Use Corollary \ref{cor:error} to obtain an $\mathcal{O}( | \Delta x | )$ approximation of $\Pr(x_t ,k,s,\hat{x}_0 , \hat{v}_0)$.
	\item Use \eqref{eq:decomposition} to compute $\Pr( x_t, \hat{x}_0, \hat{v}_0)$ and normalize in the variable $x_t$ to obtain an $\mathcal{O}( | \Delta |)$ approximation of  $\rho_t( x_t)$. 
\end{enumerate}
The first two steps are where the bulk of the work occurs.
Fortunately, these two steps are embarrassingly parallel.
For fixed $k$ and $\alpha$, the computation of $\Phi_{k,1}^t(x_0^{\alpha})$ on the interval $[-T,T]$ takes $\mathcal{O}(T)$ time using a an explicit finite difference scheme, and computation for each $(k,\alpha)$ may be performed in parallel with another such pair.
Similarly, computation $c_{k,s,\alpha}$ constitutes a series of parallel function evaluations over triples $(k,s,\alpha)$.
If the posteriors represented by the edge in \eqref{eq:pgm} are quick to compute then computation of all coefficients $c_{k,s,\alpha}$ is equally quick.
More precisely, the full computation of our approximation of $\rho_t(x_t)$ would take $\mathcal{O}( T n | \Gamma | / N )$ time given $N$ processing units and $n$ vector fields \Ram{you may just want to write all of this down as a theorem.}.


%  Describe how $\Pr(x \mid k)$, the director-fields, and $\sigma_x$ are learned without using math.
%  Math will be relegated to the appendix.
%  
%  NOTE:  Learning $\kappa$.
%  \begin{enumerate}
%  	\item Learn vector-fields
%	\item Generate approximate curves for each v.f.
%	\item Compute $\kappa_k$ of best fit for each v.f.
%	\item $\kappa = \min_k \{ \kappa_1,\dots,\kappa_n\}$.
%  \end{enumerate}
  
\section{Implementation and Experimental results} \label{sec:implementation}
  Now that the model has been described, we can illustrate a more specific implementation of the model and the process of fitting the model to a dataset.
  For the purpose of demonstration, we will use the Stanford Drone Dataset \cite{Robicquet2016}.
  More generally, we will assume that for a fixed scene we have a database of previously observed trajectories $\{ \hat{x}^1, \dots, \hat{x}^N\}$.
  From this data we will tune the parameters of the model appropriately.
  The parameters of the model which must be chosen or learned are
  
  \subsection{Learning the Vector Fields}
  Before we can even begin to learn vector-fields, we must learn the number of such vector-fields we have.
  To do this we use a simple clustering algorithm on the trajectories, to categorize them into groups.
  In principal, any clustering algorithm could accomplish this.
  For our algorithm we use the start and end point for each trajectory to obtain a point in $\mathbb{R}^4$.
  We then cluster in $\mathbb{R}^4$ using Affinity propagation.
  This clustering of the end-points induces a clustering of the trajectories.
  So we obtain clusters $S_1, \dots, S_n$ consisting of trajectories from our data set, as well as a set of unclassified trajectories, $S_0$.
  
  For each set $S_k$ we may learn a vector-field which is approximately compatible with that set.
  We'd like to only consider vector-fields who's vectors have unit magnitude because we observe many of the trajectories in the data appear to have a roughly constant speed.
  Therefore we assume the vector-field takes the form $X_k(x) = \left( \cos( \Theta_k(x) ) , \sin(\Theta_k(x)) \right)$ for some scalar function $\Theta_k(x)$.
  Learning the vector-fields then boils down to learning the scalar function $\Theta_k$.
  We will assume $\Theta_k$ takes the form
  \begin{align*}
  	\Theta_k(x) = \sum_{\alpha} \theta_{k,\alpha} L_{\alpha}(x)
  \end{align*}
  for some collection of coefficients, $\theta_{k,\alpha}$, and a fixed collection of basis functions, $L_{\alpha}$.
  In our case, we've chosen $L_{\alpha}$ to be a set of low degree Legendre polynomials.
  Learning $\Theta_k$ can be obtained by looking at all the velocities observed in the cluster, $S_k$.
  These velocities may be obtained by a low order finite difference formula.
  Upon normalizing the velocities, we obtain a unit-length velocity vectors, $v_{i,k}$, anchored at each point, $x_{i,k}$, of $S_k$.
  We can learn $\Theta_k$ by defining the cost-function
  \begin{align*}
  	C[ \Theta_k] = \sum_i \langle v_{i,k} , ( \cos(\Theta_k( x_{i,k}) , \sin( \Theta_k( x_{i,k} ) ) \rangle
  \end{align*}
  which penalizes $\Theta_k$ for producing a misalignment with the observed velocities at the observed points of $S_k$.
  When $\Theta_{k}$ includes high order polynomials (e.g. beyond 5th order), we should also include a regularization term to bias the minimizes towards smoother outputs.
  Using the $H^1$-norm times a fixed scalar would suffice.
  
  
  \subsection{Learning $\Pr( x_0 \mid M)$ and $\Pr(M)$}
  Let us begin by considering the nonlinear models first.
  That is to say, we are concerned with $M = (k,s)$ for an integer $k$ and scalar $s$.
  We'd like to compute $\Pr( x_0 \mid k,s)$ for each cluster $k=1,\dots,n$ and each speed $s \in \mathbb{R}$.
  We will make the modeling assumption that $x_0$ is independent of $s$ given $k$, i.e. $\Pr( x_0 \mid k,s) = \Pr(x_0 \mid k)$.
  Additionally, we will assume that $s$ and $k$ are independent.
  This means that we only need to learn $\Pr( x_0 \mid k)$, $\Pr(k)$, and $\Pr(s)$.
  
  We will let $\Pr(k) = (n+1)^{-1}$ and $\Pr(s) \sim \mathcal{U}( [-s_{\max}, s_{\max} ] )$
  where $s_{\max}>0$ is the largest observed speed in the dataset.  This implies that $\Pr(lin) = (n+1)^{-1}$ as well.
  Other reasonable choices (such as $\Pr(k) \propto | S_k|$) could work, but we've chosen to be more conservative in this paper.
  
  In order to learn $\Pr( x_0 \mid k)$ we will assume that it's logarithm may be approximated by a low dimensional subspace of functions on $\mathbb{R}^2$.
  That is to say, for each $k$ we will assume $\Pr( x_0 \mid k) = \frac{1}{Z_k} \exp( - V_k(x_0) )$ and $V_k$ is a function who's constant term is $0$ and is given by
  \begin{align*}
  	V_k(x_0; \mathbf{c} ) := \sum_{|\alpha|< d} c_{\alpha} L_{\alpha}( x_0)
  \end{align*}
  for a collection of basis functions, $L_{\alpha}$ and coefficients $\mathbf{c} = \{ c_{\alpha} \}_{|\alpha| < d}$.
  We chose our basis functions to be the collection of tensor products from the first $6$ Legendre polynomials, normalized to the size of the domain.
  Then, one may fit the coefficients $c_{\alpha}$ to the data by using a log-likelihood criterion.
  The resulting (convex) optimization problem takes the form
  \begin{align*}
  	\mathbf{c}^* = \inf_{ |\mathbf{c}| } \sum_{x \in S_k} V_k( x_0; \mathbf{c})
  \end{align*}
  Where the norm on $\mathbf{c}$ is a sup-norm.
  We can also bias this optimization towards more regular functions by adding a penalty to the cost function.
  
  Finally, we let $\Pr( x_0 \mid lin) \sim \mathcal{U}(D)$.
  
  \subsection{Learning the measurement model}
  We will assume a Gaussian noise model.  That is
  \begin{align*}
  	\Pr( \hat{x}_0 \mid x_0 ) \sim \mathcal{N}( x_0 , \sigma_x) \quad, \quad \Pr( \hat{v}_0 \mid v_0 ) \sim \mathcal{N}( v_0, \sigma_v).
  \end{align*}
  Therefore, our model is parametrized by the standard deviations $\sigma_x$ and $\sigma_v$.
  We will assume that the true trajectory of an agent is fairly smooth compared to the noisy output of our measurement device.
  This justifies smoothing the trajectories, and using the difference between the smoothed signals and the raw data to learn the variance $\sigma_x$.
  To obtain the results in this paper we have used a moving average of $4$ time steps (this is $0.13$ seconds in realtime).
  We set $\sigma_v = 2 \sigma_x / \Delta t$ where $\Delta t > 0$ is the time-step size.  This choice is justified from the our use of finite difference's to estimate velocity.
  In particular, if velocity is approximated via finite differencing as $v(t) \approx (x(t+h) - x(t))\,\Delta t^{-1} + \mathcal{O}(h)$
  and the measurements are corrupted by Gaussian noise, then the measurement $\hat{v}(t)$ is related to $v(t)$ by Gaussian noise with roughly the same standard deviation as $(x(t+h) - x(t))\,\Delta t^{-1}$.
  
  \subsection{Learning the noise model}
  Finally, we assume that the true position is related to the model by Gaussian noise with a growing variance.
  In particular, we assume $\Pr( x_t \mid \check{x}_t) \sim \mathcal{N}( \check{x}_t , \kappa t)$ for some constant $\kappa \geq 0$.
  The parameter, $\kappa$, must be learned.
  We've taken an ad hoc approach in this paper, although more intelligent and theoretically sound alternatives likely exist.
  For each curve in $S_k$ we create a synthetic curve using the initial position and speed and integrating the corresponding vector-field, $s\, X_k$.
  So for each curve, $x_i(t)$, of $S_k$, we have a synthesized curve $x_{i,synth}(t)$ as well.
  We then measure the standard deviation of $(x_i(t) - x_{i,synth}(t)) / t$ over $i$ and at few time, $t \in \{ 0, 100, 200 \}$ in order to obtain $\kappa$.
  
 \subsection{ Precision, accuracy, etc.}
In this section we establish our methods for evaluating the quality of our predictions, and comparing them against the model from [8] and a random walk.
We implemented our model as well as the evaluation code in Python 2.6. Our implementation is available online \footnote{https://github.com/hoj201/pedestrian\_forecasting}.

%\begin{figure}
%\includegraphics[width=0.5\textwidth]{figures/coupa_vis.eps}
%\caption{Trajectory batches sampled for cross validation}
%\label{fig:data_set}
%\end{figure}



Our data came from the Stanford Drone Dataset, in the form of hand annotated bounding boxes around agents (e.g. cars, pedestrians, bicycles). Our datasets used the bicycle data. We did a 10-fold cross validation on 4 different scenes of varying complexity. Our analysis used the same partitions of the trajectories for all three predictors. There .% shows the sample for the ``Coupa'' scene from the Stanford Dataset.

\todo[inline]{include visualization of vector fields \& learned value function?}

The algorithm provided by Kitani et. al. was given additional information when making predictions that neither ours nor the random walk model were provided, namely the endpoint of the test trajectory. Without these data the implementation of the predictor provided by the authors devolves into a random walk.
\todo[inline]{\\figure{ All three algorithms side by side}
\\caption{The grid used to evaluate the predicted distributions. The circle denotes the start of a trajectory and the X denotes the end. } }

The output distributions of the three algorithms were compared using their integrals over the cells of a suitably fine regular grid over our domain. These integrals can be seen in {figure n}. 
In keeping with our measurement model, the ground truth compared against was a grid that was identically zero except on a bounding box around the measurement at time $t$. The dimensions of the bounding box were the average bounding box dimensions in the training data set. 
\todo[inline]{figure{plot}}
\label{fig:auc_vs_time}
\label{fig:total_rocs}

%\figure{Ours vs kitani, show confidence }
%\caption{Though Kitani et. al.'s algorithm has superior data, we see that our algorithm's uncertainty makes our algorithm safer to use than theirs.}

Disregarding small time scales where any algorithm will be reasonably accurate, our predictor behaves much better than any of the others at moderately large $t$, where we capture the  behavior of the agent without suffering the misplaced confidence observed in Kitani et. al.'s predictions. At large $t$, their aptitude comes from knowing the end point of the trajectory.
\begin{table}
\begin{center}
	\caption{Runtimes}
	\label{tab:time}
	\renewcommand{\arraystretch}{1.5}% Spread rows out...
	\begin{tabular}{||c | c c  c ||} 
		\hline
		& Our Predictor & Random Walk & Kitani et. al. \\ [0.5ex] 
		\hline 
		$\frac{\mathrm{time}}{\mathrm{frame}}$ & 0.0169s & flop & 0.0614s \\
		\hline
		
	\end{tabular}
	

\end{center}
\end{table}

The running time per frame for each algorithm was generated using run times for 400 frames, averaged across several agents and scenes, shown in Table~\ref{tab:time}. Our algorithm implementation leveraged its embarassing parallelism using a relatively naive parallelization scheme, which split the computation of frames among 18 cores. It's highly probable that our run times would significantly decrease using an implementation of our algorithm in C that uses a more clever scheme. Kitani et. al. was timed with minimal modification to the source code provided by the authors. 

We see that under our current implementation, we are beating Kitani et. al.'s algorithm at the relevant time scales, and are running more than 3 times faster that their algorithm. More significantly, our algorithm runs at almost 60FPS. Figure \ref{fig:auc_vs_time} shows that at all time scales, our algorithm has very good predictive capability, and Figure \ref{fig:ours_grid} shows the qualitative merit of our predictions on several scenes.



\section{Conclusion} 
\label{sec:conclusion}

Avenues of improvement:
update predictions when given additional measurements

The conclusion goes here.

\section*{Acknowledgments}
Thanks to Kris Kitani for being nice.  No thanks to Stanford, for being dicks.

\appendix
\subsection{Inverse Optimal Control} \label{app:ioc}
One of the valuable aspect of the motion model of \cite{Kitani2012} was that the trajectories were solutions of optimal control problems.
This is a desirable property for a motion model of pedestrians/cyclists/vehicles in that it seems reasonable to assume that we all move through the world with an intent to get somewhere.
This framework was dubbed \emph{inverse optimal control} (IOC).
Here we illustrate how solutions of \eqref{eq:ode} can fit within the IOC framework.

\begin{thm}
	Let $X$ be a vector-field such that $\| X(x) \|_2 = 1$ for all $x \in \mathbb{R}^2$.
Then, for each initial condition $x_0 \in \mathbb{R}^2$, there exists a neighborhood $U$, a Riemannian metric, $g$, and a cost function, $f$, 
such that solutions of \eqref{eq:ode} are also solutions of the optimal control problem
\begin{align}
	p^* = \inf_{ \| v_t \|_g = s } \int_0^T f( x_t) dt \label{eq:IOC}
\end{align}
where $v_t = \frac{d x_t}{dt}$, $\| \cdot \|_g$ is the norm with respect to $g$ and the infimum is taken over all differentiable curves in $U$ which originate from $x_0$.
\end{thm}

\begin{proof}
	By rescaling time, we may let $s$ be any positive real number.
	Therefore, without loss of generality, we will seek an $f$ and $g$ such that $s=1$.
	In this case a solution of \eqref{eq:IOC} is generated by the vector-field $X = \frac{\nabla f}{ \| \nabla f\|}$ where $\nabla$ is the Riemannian gradient with respect to some metric (possibly non-Euclidean).
	Therefore, our goal is to illustrate that there exists a metric $g$ and a function $f$ such that the given $X$ is given by $\frac{\nabla f}{ \| \nabla f\|}$.

	Because $\| X \| = 1$ globally, it has no fixed points.
	From the flow-box theorem \cite[Theorem 4.1.14]{MTA} we can assert that for any open set, $U \subset \mathbb{R}^2$ there exists a local diffeomorphism which transforms $X_k$ into a flat vector-field.
	Mathematically, this asserts the existence of a map $\Phi : U \to V \subset \mathbb{R}^2$ such that the push-forward of $X$, which we will denote by $\tilde{X}$, and given by
	\begin{align*}
		\tilde{X}(\tilde{x}) = \Phi_* X(\tilde{x}) := \left. D\Phi \right|_{\Phi^{-1}(\tilde{x}) } \cdot X(  \Phi^{-1}(\tilde{x}) ),
	\end{align*}
	is just the flat vector field $(1,0)$ for all $x \in U$.
	We could view the coordinate function $\tilde{f}(x) = x^0$ as a cost function on $V$,
	and we may set $g_V$ to be equal to the standard flat metric on $V$ inherited from $\mathbb{R}^2$.
	In this case we observe that $\tilde{X}$ generates solutions to the optimization problem
	\begin{align*}
		\tilde{p}^* = \inf_{ \| \tilde{v}_t \|_{g_V} \leq 1} = \int_0^T \tilde{f}( \tilde{x}_t ) dt
	\end{align*}
	By a change of variables, it follows that the original vector field, $X$, then solves the optimization problem \eqref{eq:IOC}
	where $g = \Phi^* g_V$ is the pull-back metric, and $f = \Phi^* \tilde{f}$ is the pull-back of $\tilde{f}$.
\end{proof}


%% Use plainnat to work nicely with natbib. 

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}


