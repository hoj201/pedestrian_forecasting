\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Helbing1992}
\citation{kalman1960new}
\citation{Schneider2013}
\citation{Kooji2014}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The performance of the presented algorithm captures the most probable routes that a pedestrian chooses. In this figure, the dot is the start point of the test trajectory, the diamond is the position at time $t$, and the X is the end of the trajectory. The likelihood of detection is depicted using the \textit  {virdis} color palette. In this example which was captured at thirty frames per second, the presented algorithm took 0.0158s per frame in a Python implementation. \relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gates-1-2}{{1}{1}{The performance of the presented algorithm captures the most probable routes that a pedestrian chooses. In this figure, the dot is the start point of the test trajectory, the diamond is the position at time $t$, and the X is the end of the trajectory. The likelihood of detection is depicted using the \textit {virdis} color palette. In this example which was captured at thirty frames per second, the presented algorithm took 0.0158s per frame in a Python implementation. \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {I-A}Background}{1}{subsection.1.1}}
\citation{Ziebart2008}
\citation{Ziebart2009}
\citation{Kitani2012}
\citation{Xie2013}
\citation{Karasev2016}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Karasev2016}
\citation{Karasev2016}
\citation{Doucet2000}
\citation{Ballan2016}
\citation{Karasev2016}
\citation{Ballan2016}
\citation{Ballan2016}
\citation{Walker2014}
\citation{Walker2014}
\citation{Kitani2012}
\citation{Walker2014}
\citation{Karasev2016}
\citation{Ballan2016}
\citation{Kitani2012}
\citation{Karasev2016}
\citation{Robicquet2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {I-B}Contributions}{2}{subsection.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Model}{2}{section.2}}
\newlabel{sec:model}{{II}{2}{Model}{section.2}{}}
\citation{MTA}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}The Variables of the Model}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}The Sensor Model}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}The Agent Model}{3}{subsection.2.3}}
\newlabel{eq:ode}{{2}{3}{The Agent Model}{equation.2.2}{}}
\newlabel{eq:x_check | ksx}{{3}{3}{The Agent Model}{equation.2.3}{}}
\newlabel{eq:v | ksx}{{4}{3}{The Agent Model}{equation.2.4}{}}
\newlabel{eq:models}{{5}{3}{The Agent Model}{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-D}The Full Model}{3}{subsection.2.4}}
\newlabel{eq:pgm}{{6}{3}{The Full Model}{equation.2.6}{}}
\citation{Leveque1992}
\citation{Gottlieb2001}
\newlabel{eq:decomposition}{{8}{4}{The Full Model}{equation.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Efficient Probability Propagation}{4}{section.3}}
\newlabel{sec:efficient}{{III}{4}{Efficient Probability Propagation}{section.3}{}}
\newlabel{eq:approximation 0}{{9}{4}{Efficient Probability Propagation}{equation.3.9}{}}
\newlabel{eq:convolve}{{12}{4}{Efficient Probability Propagation}{equation.3.12}{}}
\newlabel{eq:push forward}{{17}{4}{Efficient Probability Propagation}{equation.3.17}{}}
\newlabel{eq:approximation 1}{{18}{4}{Efficient Probability Propagation}{equation.3.18}{}}
\newlabel{eq:makesense}{{19}{4}{Efficient Probability Propagation}{equation.3.19}{}}
\newlabel{thm:error}{{1}{5}{Efficient Probability Propagation}{thm.3.1}{}}
\newlabel{cor:error}{{1}{5}{Efficient Probability Propagation}{cor.1}{}}
\newlabel{eq:approximation 2}{{20}{5}{Efficient Probability Propagation}{equation.3.20}{}}
\newlabel{thm:symmetry}{{2}{5}{Efficient Probability Propagation}{thm.3.2}{}}
\newlabel{thm:main}{{3}{5}{Efficient Probability Propagation}{thm.3.3}{}}
\newlabel{eq:approximation 3}{{25}{5}{Efficient Probability Propagation}{equation.3.25}{}}
\newlabel{eq:partition}{{26}{5}{Efficient Probability Propagation}{equation.3.26}{}}
\citation{Robicquet2016}
\citation{FreyDueck2007}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Algorithm to compute $\rho _t$ for each $t \in \{\Delta t, 2 \Delta t, \dots  , N_t \Delta t$\}.\relax }}{6}{algorithm.1}}
\newlabel{alg:1}{{1}{6}{Algorithm to compute $\rho _t$ for each $t \in \{\Delta t, 2 \Delta t, \dots , N_t \Delta t$\}.\relax }{algorithm.1}{}}
\newlabel{alg1:step2}{{6}{6}{Algorithm to compute $\rho _t$ for each $t \in \{\Delta t, 2 \Delta t, \dots , N_t \Delta t$\}.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Implementation and Experimental results}{6}{section.4}}
\newlabel{sec:implementation}{{IV}{6}{Implementation and Experimental results}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Learning the Vector Fields}{6}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Learning $\qopname  \relax m{Pr}( x_0 \mid M)$ and $\qopname  \relax m{Pr}(M)$}{6}{subsection.4.2}}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Robicquet2016}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Kitani2012}
\citation{Kitani2012}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An illustration of the predictions generated by the various algorithms. In this figure, the dot is the start point of the test trajectory, the diamond is the position at time $t$, and the X is the end of the trajectory. The likelihood of detection is depicted using the \textit  {virdis} color palette. Notice that the Random Walk is imprecise, while the predictions generated by the algorithm in \cite  {Kitani2012} suffer from the inability of their motion model to adequately match the speed of the agent.\relax }}{7}{figure.caption.2}}
\newlabel{fig:bookstore-1-2}{{2}{7}{An illustration of the predictions generated by the various algorithms. In this figure, the dot is the start point of the test trajectory, the diamond is the position at time $t$, and the X is the end of the trajectory. The likelihood of detection is depicted using the \textit {virdis} color palette. Notice that the Random Walk is imprecise, while the predictions generated by the algorithm in \cite {Kitani2012} suffer from the inability of their motion model to adequately match the speed of the agent.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Learning the Measurement Model}{7}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-D}Learning the Noise Model}{7}{subsection.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An illustration of the predictions generated by the various algorithms. In this figure, the dot is the start point of the test trajectory, the diamond is the position at time $t$, and the X is the end of the trajectory. The likelihood of detection is depicted using the \textit  {virdis} color palette. Notice that the Random Walk is imprecise, while the predictions generated by the algorithm in \cite  {Kitani2012} are unable to match the speed of the agent and choose the wrong direction to follow the agent around the circle.\relax }}{7}{figure.caption.3}}
\newlabel{fig:death-1-2}{{3}{7}{An illustration of the predictions generated by the various algorithms. In this figure, the dot is the start point of the test trajectory, the diamond is the position at time $t$, and the X is the end of the trajectory. The likelihood of detection is depicted using the \textit {virdis} color palette. Notice that the Random Walk is imprecise, while the predictions generated by the algorithm in \cite {Kitani2012} are unable to match the speed of the agent and choose the wrong direction to follow the agent around the circle.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-E}Evaluating Performance}{7}{subsection.4.5}}
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{Helbing1992}{1}
\bibcite{kalman1960new}{2}
\bibcite{Schneider2013}{3}
\bibcite{Kooji2014}{4}
\bibcite{Ziebart2008}{5}
\bibcite{Ziebart2009}{6}
\bibcite{Kitani2012}{7}
\bibcite{Xie2013}{8}
\bibcite{Karasev2016}{9}
\bibcite{Doucet2000}{10}
\bibcite{Ballan2016}{11}
\bibcite{Walker2014}{12}
\bibcite{Robicquet2016}{13}
\bibcite{MTA}{14}
\bibcite{Leveque1992}{15}
\bibcite{Gottlieb2001}{16}
\bibcite{FreyDueck2007}{17}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A comparison of the AUC of the various algorithms. Note that the initial dip in the performance of \cite  {Kitani2012} is due to their confidence in their initial estimate.\relax }}{8}{figure.caption.4}}
\newlabel{fig:auc_vs_time}{{4}{8}{A comparison of the AUC of the various algorithms. Note that the initial dip in the performance of \cite {Kitani2012} is due to their confidence in their initial estimate.\relax }{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Comparison of runtimes of the various algorithms.\relax }}{8}{table.caption.5}}
\newlabel{tab:time}{{I}{8}{Comparison of runtimes of the various algorithms.\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{8}{section.5}}
\newlabel{sec:conclusion}{{V}{8}{Conclusion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{References}{8}{section*.7}}
